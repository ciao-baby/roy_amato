{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO76peo//u7e6Eq+Zn9gmmh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciao-baby/roy_amato/blob/main/roy_amato_revised_deliverable_1_project_1_university_id_u01862158.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# URL Credibility Scoring Prototype\n",
        "# --------------------------------------------\n",
        "# Demonstrates core functionality:\n",
        "# 1. Accept URLs as input\n",
        "# 2. Fetch and process webpage data\n",
        "# 3. Generate a basic credibility score\n",
        "# 4. Display results in a simple format\n",
        "# ============================================\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import tldextract\n",
        "\n",
        "def get_credibility_score(url):\n",
        "    score = 50  # Start with neutral base score\n",
        "    info = {}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        info[\"status_code\"] = response.status_code\n",
        "\n",
        "        # --- HTTPS Check ---\n",
        "        if url.startswith(\"https://\"):\n",
        "            score += 10\n",
        "            info[\"https\"] = \"Yes\"\n",
        "        else:\n",
        "            info[\"https\"] = \"No\"\n",
        "\n",
        "        # --- Domain Analysis ---\n",
        "        domain_info = tldextract.extract(url)\n",
        "        domain = f\"{domain_info.domain}.{domain_info.suffix}\"\n",
        "        info[\"domain\"] = domain\n",
        "\n",
        "        if domain.endswith((\".edu\", \".gov\")):\n",
        "            score += 20\n",
        "        elif domain.endswith((\".org\", \".com\")):\n",
        "            score += 5\n",
        "        elif domain.endswith((\".biz\", \".info\", \".xyz\")):\n",
        "            score -= 15\n",
        "\n",
        "        # --- Content Analysis ---\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        title = soup.title.string if soup.title else \"No title found\"\n",
        "        info[\"title\"] = title.strip()[:80]  # Truncate for readability\n",
        "\n",
        "        text = soup.get_text(separator=\" \", strip=True)\n",
        "        word_count = len(text.split())\n",
        "        info[\"word_count\"] = word_count\n",
        "\n",
        "        if word_count < 200:\n",
        "            score -= 10\n",
        "        elif word_count > 1000:\n",
        "            score += 5\n",
        "\n",
        "        # --- Clamp Score & Label ---\n",
        "        score = max(0, min(100, score))\n",
        "\n",
        "        if score < 40:\n",
        "            label = \"Low\"\n",
        "        elif score < 70:\n",
        "            label = \"Medium\"\n",
        "        else:\n",
        "            label = \"High\"\n",
        "\n",
        "        # --- Return Results ---\n",
        "        return {\n",
        "            \"url\": url,\n",
        "            \"domain\": info[\"domain\"],\n",
        "            \"https\": info[\"https\"],\n",
        "            \"title\": info[\"title\"],\n",
        "            \"word_count\": info[\"word_count\"],\n",
        "            \"score\": score,\n",
        "            \"label\": label\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"url\": url,\n",
        "            \"error\": str(e),\n",
        "            \"score\": 0,\n",
        "            \"label\": \"Unavailable\"\n",
        "        }\n",
        "\n",
        "# --- Main Program ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üîç URL Credibility Scoring Prototype\")\n",
        "    print(\"Enter URLs separated by spaces:\")\n",
        "    urls = input(\"> \").split()\n",
        "\n",
        "    print(\"\\n=== Results ===\\n\")\n",
        "    for url in urls:\n",
        "        result = get_credibility_score(url)\n",
        "        if \"error\" in result:\n",
        "            print(f\"URL: {result['url']}\")\n",
        "            print(f\"  ‚ùå Error: {result['error']}\\n\")\n",
        "        else:\n",
        "            print(f\"URL: {result['url']}\")\n",
        "            print(f\"  Domain: {result['domain']}\")\n",
        "            print(f\"  HTTPS: {result['https']}\")\n",
        "            print(f\"  Title: {result['title']}\")\n",
        "            print(f\"  Word Count: {result['word_count']}\")\n",
        "            print(f\"  Credibility Score: {result['score']} ({result['label']})\\n\")\n"
      ],
      "metadata": {
        "id": "xHqd7z1MLhgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}