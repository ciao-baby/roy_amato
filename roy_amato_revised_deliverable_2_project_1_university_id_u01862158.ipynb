{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMEbThuPXbWXRkIWNrxv0z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciao-baby/roy_amato/blob/main/roy_amato_revised_deliverable_2_project_1_university_id_u01862158.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jff7RcjgTnwM"
      },
      "outputs": [],
      "source": [
        "# request JSON\n",
        "\n",
        "  {\n",
        "  \"urls\": [\"https://example.com/article1\", \"https://example.com/article2\"],\n",
        "  \"options\": {\n",
        "    \"fetch_social\": true,\n",
        "    \"max_fetch_time_seconds\": 6,\n",
        "    \"explain\": true,\n",
        "    \"mode\": \"hybrid\"  // options: \"heuristic\", \"ml\", \"hybrid\"\n",
        "  }\n",
        "}\n",
        "\n",
        "# Response JSON (per URL)\n",
        "{\n",
        "  \"url\": \"https://example.com/article1\",\n",
        "  \"status\": \"ok\",\n",
        "  \"score\": 72.4,\n",
        "  \"label\": \"High\",\n",
        "  \"breakdown\": {\n",
        "    \"source_score\": 25,\n",
        "    \"technical_score\": 8,\n",
        "    \"content_score\": 30,\n",
        "    \"social_score\": 9\n",
        "  },\n",
        "  \"top_features\": [\n",
        "    {\"feature\":\"domain_reputation\",\"value\":0.92,\"contribution\":12.0},\n",
        "    {\"feature\":\"https\",\"value\":true,\"contribution\":5.0},\n",
        "    {\"feature\":\"citation_count\",\"value\":3,\"contribution\":6.0}\n",
        "  ],\n",
        "  \"raw\": {\n",
        "    \"title\":\"Article title\",\n",
        "    \"word_count\":1200,\n",
        "    \"domain\":\"example.com\"\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement the python function it is essential to test the validity of the data being reported by accessing the the URL of each reference. A prototype must first be developed where we utilize a modular pipeline. Deterministic heuristics and LR aggregator are essential as well as baseline data received from sources like CREDBANK. The next phase is designed to run ablation studies on calibrated outputs for the purpose of calibrating thresholds claims. Here we can add LightGBM/XGBoost aggregator as well. Additionally, we can add a simple claim extraction and FEVER style retrieval for claim verification where we find detectable checkable claims. The next phase would involve the integration of a distilled transformer encoder for text verification as well as SHAP based explainers. Here we can build a retrieval and LLM guided verification loop to address complex claims and avoid hallucinations. In the final phase we can add a streaming score for social monitoring, and a scale with microservices and model serving as well. Therefore, in the production scale we have a continuous learning pipeline including a human-in-the-loop, labeling and performing scheduled retraining."
      ],
      "metadata": {
        "id": "Zf82nHyeX79-"
      }
    }
  ]
}